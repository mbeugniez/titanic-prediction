---
title: "Rapport du Projet Titanic Survival Prediction"
author: "√âquipe BUT 3 Sciences des Donn√©es"
date: "2025-01-30"
output: github_document
---

# 1. Introduction

Dans le cadre de notre formation en **BUT 3 Sciences des Donn√©es**, nous avons r√©alis√© un projet d‚Äôing√©nierie logicielle appliqu√© √† un probl√®me de **Machine Learning**. Ce projet s‚Äôinscrit dans la mise en pratique des comp√©tences acquises en **modularisation du code, documentation, tests unitaires et int√©gration continue**.

Nous avons travaill√© sur le **Titanic Survival Prediction**, un projet classique en **Data Science**, consistant √† pr√©dire la survie des passagers du Titanic √† partir de diverses caract√©ristiques (**classe, sexe, nombre de proches √† bord, etc.**). Notre objectif √©tait non seulement d‚Äôam√©liorer la qualit√© du mod√®le, mais aussi de **refactoriser le code en suivant les bonnes pratiques d‚Äôing√©nierie logicielle**.

---

# 2. Objectifs du Projet

Ce projet nous a permis d‚Äôatteindre plusieurs objectifs p√©dagogiques et techniques :

- **Structurer un projet de Machine Learning** en modules ind√©pendants et r√©utilisables.
- **Appliquer les bonnes pratiques de d√©veloppement** (conformit√© √† PEP 8, modularisation, docstrings, etc.).
- **Mettre en place des tests unitaires** pour garantir la fiabilit√© du code.
- **Automatiser les processus avec une pipeline CI/CD** (tests automatiques via GitHub Actions).
- **Collaborer efficacement en utilisant Git et GitHub**.

L‚Äôapproche adopt√©e repose sur la s√©paration des diff√©rentes t√¢ches en modules bien d√©finis :

1. **Pr√©traitement des donn√©es** (nettoyage, transformation des variables cat√©gorielles, encodage).
2. **Entra√Ænement du mod√®le** (Random Forest avec ajustement des hyperparam√®tres).
3. **√âvaluation du mod√®le** (pr√©dictions sur les donn√©es test et soumission du fichier de r√©sultats).

---

# 3. Instructions d‚ÄôInstallation et d‚ÄôUtilisation

## 3.1 Pr√©requis

Avant de commencer, assurez-vous d‚Äôavoir :

- **Python 3.8+** install√© sur votre machine.
- Un **environnement virtuel** pour isoler les d√©pendances (*optionnel mais recommand√©*).
- Les **biblioth√®ques requises** list√©es dans `requirements.txt`.

---

## 3.2 Installation

###  ** Cloner le d√©p√¥t GitHub**
```bash
git clone https://github.com/votre-repo/titanic-prediction.git
cd titanic-prediction
```

###  ** Installer les d√©pendances**
Nous recommandons l'utilisation d'un **environnement virtuel** :

```bash
python -m venv venv
venv\Scripts\activate 
pip install -r requirements.txt
```

###  **T√©l√©charger les donn√©es**
Les fichiers `train.csv` et `test.csv` doivent √™tre plac√©s √† la racine du projet.

**Lien vers le dataset :** [üîó Titanic Dataset - Kaggle](https://www.kaggle.com/competitions/titanic/data)

---

## 3.3 Utilisation

###  **Ex√©cuter le pr√©traitement des donn√©es**
```bash
python src/data_preprocessing.py
```

###  **Entra√Æner le mod√®le**
```bash
python src/model_training.py
```

###  **Faire des pr√©dictions et g√©n√©rer le fichier de soumission**
```bash
python src/model_evaluation.py
```

###  **Effectuer les tests unitaires**
```bash
pytest tests/
```

---

# 4. Contributions des Membres de l‚Äô√âquipe

Dans le cadre de ce projet, chaque membre de l‚Äô√©quipe a contribu√© √† une partie essentielle du d√©veloppement. **Pr√©cy** s‚Äôest occup√©e de la refactorisation du code, en transformant le notebook Kaggle en scripts Python modulaires et en assurant la qualit√© du code selon les standards PEP 8. **Meriam** a pris en charge l‚Äôajout des tests unitaires pour garantir la fiabilit√© des fonctions de pr√©traitement et du mod√®le. **Awa** a r√©dig√© la documentation, incluant les docstrings et un fichier README d√©taillant les objectifs et l‚Äôutilisation du projet. **Ma√´lle** a mis en place l‚Äôenvironnement de collaboration avec Git et GitHub, en organisant les branches et les workflows. Enfin, l‚Äôensemble de l‚Äô√©quipe a travaill√© collectivement sur l‚Äôimpl√©mentation de la pipeline CI/CD, automatisant les tests, le linting et l‚Äôint√©gration continue afin d‚Äôassurer la stabilit√© du projet.

Chaque membre a √©galement contribu√© √† la **relecture et √† l‚Äôam√©lioration du code** en respectant les bonnes pratiques d‚Äôing√©nierie logicielle.

---

# 5. Conclusion

Ce projet nous a permis d‚Äôacqu√©rir une **exp√©rience concr√®te en ing√©nierie logicielle appliqu√©e √† la Data Science**. Nous avons appris √† **structurer un projet ML de mani√®re rigoureuse**, √† **automatiser des t√¢ches essentielles** et √† **travailler efficacement en √©quipe avec Git/GitHub**.

Gr√¢ce √† l‚Äôimpl√©mentation de **tests unitaires et d‚Äôun pipeline CI/CD**, notre projet est d√©sormais **plus robuste et plus fiable**, garantissant une **meilleure reproductibilit√© des r√©sultats**.

 **Ce projet nous a pr√©par√©s aux exigences du monde professionnel en combinant Data Science et Ing√©nierie Logicielle.** 